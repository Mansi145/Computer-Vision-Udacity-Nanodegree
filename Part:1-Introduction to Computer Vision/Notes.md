# Vision Systems

### Computer Vision Course Overview
This Nanodegree program is broken into three main sections:

1. **Intro to Computer Vision**, which covers topics like image processing, feature extraction done manually or through training a convolutional neural network (CNN) using PyTorch.
2. **Advanced Computer Vision and Deep Learning**, which is all about advances in deep learning architectures like region-based CNN's, YOLO and single-shot detection algorithms, and CNN's used in combination with recurrent neural networks.
3. **Object Tracking and Localization**, which covers how a robot can move and sense the world around it, creating a visual representation of the world as it navigates. </br>
Each of these three sections will have an associated project that allows you to demonstrate the skills you've learned in each part.

### 1)Compound Eyes
Bees have compound eyes, which are many tiny eyes bundled together. Compound eyes consist of multiple lenses (as many as 30,000 lenses in a single compound eye); each lens is responsible for focusing light and forming a small section of an image, which allows an insect to see a composite image that’s pieced together from the input that each lens receives! Bee's eyes have really low resolution, so they’re not so great at recognizing things from a distance, but they’re very sensitive to motion, which is essential while flying fast! </br>
There are a variety of vision systems, each with their own strengths, and this is something to keep in mind when we start building and designing systems to perform specific visual tasks in future lessons.
[Reference](https://www.reference.com/science/compound-eyes-362b8e2642846797#)

### 2)Spatial Coherent Data 
One cool thing about computer vision, is that the techniques that we will learn about, need not only be used with camera images - but also images created with other sensors. So those techniques that you will learn, will be useful for any data, that has what we call, “spatial coherency”.
And spatially coherent data can be thought of as any data that predictably varies over space, like sound, for example. If you hear sound from a speaker close up it will sound very loud, but the farther you get away, the softer the sound will get. And so the volume of a sound can give you spatial information!

# NVIDIA
- BB8 - 
- DRIVE PX -
- JETSON TX -
- TensorRT -
- ISAAC -
